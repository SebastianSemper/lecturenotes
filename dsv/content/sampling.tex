%
Als ersten Schritt der digitalen Signalverarbeitung wollen wir uns den \"Ubergang von einem analogen Signal zu einem digitalen n\"aher ansehen.
Intuitiv k\"onnen wir diesen Vorgang in vielen Anwendungen beobachten.
Wir nehmen im Tonstudio mit einem Mikrofon Ton auf und eine Soundkarte wandelt das analoge Signal in einen WAV-Datenstrom um.
In einer Fotokamera, trifft ein Feld von Lichtstrahlen ein und wird von einem \gls{cmos}-Sensor \q{direkt} abgetastet und in Helligkeitswerte pro Farbkanal umgewandelt.
Eine Antenne wandelt ein anliegendes elektro-magnetisches Feld in eine Spannung um, welche nachtr\"aglich von einem \gls{adc} abgetastet und quantisiert wird.

Mathematisch modellieren wir analoge Signale $s_a : D \rightarrow B$ meist mit $D$ und $B$, die auf die reellen Zahlen $\R$ zur\"uckgreifen.
Die Wandlung von analog zu digital transformiert dieses Signal in eine Funktion $s: \Z \rightarrow Q$ um, wobei auch $\Abs{Q} < \infty$ gilt.
Das hei\ss{}t, dass das Signal nach AD-Wandlung nur noch endliche Werte annehmen kann und, dass es nur noch aus eine \emph{Folge} von Werten aus der Menge $Q$ besteht. 
Es wurde also zeit- und wertdiskretisiert.
Wir werden uns zun"achst nur mit der Diskretisierung in Zeit befassen, weil es einfach einfacher ist.
Das hei"st, dass wir uns vorstellen, dass das diskretisierte Signal nur an einer diskreten Menge an Punkten noch Informationen "uber das abgetastete Signal beinhaltet.
Weiterhin sind wir nicht an der physikalischen Umsetzung von \glspl{adc} interessiert, sondern h"ochstens an deren systemtheoretischer Modellierung.

Die zentralen Fragen sind nun:
\begin{itemize}
    \item Wie muss der Vorgang der Abtastung gestaltet sein, dass keine Information verloren geht?
    \item Wie k\"onnen wir die Eigenschaften des analogen Signals in dessen abgetasteter Version wiederfinden?
    \item Wie k"onnen wir eine Intuition f"ur den Vorgang der Abtastung entwickeln?
\end{itemize}
%
\subsection{Frequenz von Signalen}
%
\subsubsection{Zeit-Kontinuierliche Sinussignale}
%
Meistens werden wir uns in der Vorlesung mit reell- oder komplexwertigen Zeitsignalen befassen, d.h. wir modellieren unsere Signale als $x_a : \R \rightarrow \R$ oder $x_a: \R \rightarrow \C$.
Wobei physikalische Signale nat"urlich nur reellwertig sind, doch manchmal ist die Darstellung als komplexwertige Funktion besser handhabbar, siehe \eqref{complex_baseband}.
Das hei"st, dass die Abtastung im Zeitbereich vonstatten geht, was sofort den Begriff der \emph{Frequenz} auf den Plan ruft, da Frequenz mit Einheit $1/[s]$ eng mit Zeit $[s]$ verkn"upft ist.

Betrachten wir also erst einmal, welchen Einfluss Abtastung von Signalen mit einzelnen Frequenzen hat, am Beispiel von
%
\begin{equation}\label{eq:analog_cosine}
    x_a(t) = A \cos(\Omega t + \theta),
\end{equation}
%
wobei wir hier $A \in \R$ als Amplitude, $\Omega \in \R^+_0$ als Kreisfrequenz $\SI{1}{\radian\per\second}$, $t \in \R$ als Zeit $\SI{1}{\second}$ und die Phase $\theta \in \R$ mit Einheit $\SI{1}{\radian}$ nutzen.
Alternativ k"onnen wir auch zur Frequenz $F \in \R$ $\SI{1}{\per\second} = \SI{1}{\hertz}$ "ubergehen.
Dann erhalten wir
\[
x_a(t) = A \cos(2 \pi F t + \theta).
\]
Diese Funktion ist in \cref{fig:analog_cosine} dargestellt.
Wir sehen, dass die Funktion periodisch ist mit Periode $T_p = 1/F$.

\myemph{Das hei"st, dass $x_a(t + k \cdot T_p)$ f"ur $k \in \Z$ nicht vom Signal $x_a(t)$ zu unterscheiden ist!}

\begin{figure}[t]
    \begin{center}
        \includegraphics[width=0.48\textwidth]{img/sampling/analog_cosine.png}
        \includegraphics[width=0.48\textwidth]{img/sampling/two_phasors.png}
    \end{center}
    \caption{$x_a(t) = A \cos(2 \pi F t + \theta)$, Quelle: \cite{proakis2013}}\label{fig:analog_cosine}
\end{figure}
%
Es gibt noch eine alternative Darstellung von der obigen Funktion durch die Addition von zwei \emph{Phasoren} als
\[
    x_a(t) 
        = A \cos(2 \pi F t + \theta) 
        = \frac A2 \exp(\jmath (\Omega t + \theta)) 
            + \frac A2 \exp(- \jmath (\Omega t + \theta)).
\]
Da die beiden "uberlagerten Phasoren so interpretiert werden k"onnen als rotierten diese in gegens"atzliche Richtungen, ist es gerechtfertigt der physikalischen Intuition entgegen auch von \q{negativen} Frequenzen zu sprechen.
Wir erlauben also $F \in \R$, womit auch der Spezialfall $T_p = \infty$, also $x_a(t) = A$ abgedeckt ist.
Ein kleines Beispiel findet man in \Cref{py:cont_harms}.
%
\begin{listing}
    \begin{minipage}{0.49\textwidth}
        \inputminted[firstline=4]{python3}{code/cont_harms.py}
    \end{minipage}%
    \begin{minipage}{0.49\textwidth}
        \strut\vspace*{-\baselineskip}\newline
        \includegraphics[width=\textwidth]{code/cont_harms.png}
    \end{minipage}
    \codecaption{code/cont_harms.py}{Berechnung und Darstellung von \eqref{eq:analog_cosine}}\label{py:cont_harms}
\end{listing}
\FloatBarrier
%
\subsubsection{Zeit-Diskrete Sinussignale}
%
Als n"achstes gehen wir zu dem eigentlich interessanten Fall "uber, bei welchem wir von zeitdiskreten harmonischen Signalen sprechen.
Dabei gehen wir vorerst \emph{nicht} davon aus, dass das Signal durch Abtastung eines analogen Signals entstanden ist, sondern betrachten es ganz losgel"ost f"ur sich.
In Analogie zu \eqref{eq:analog_cosine} definieren wir
%
\begin{equation}\label{eq:discrete_cosine}
    x[n] = A \cos(\omega n + \theta) = A \cos(2 \pi f n + \theta).
\end{equation}
%
Wichtig bei diskreten Signalen ist, dass ihre physikalische Interpretierbarkeit nicht direkt gegeben ist, da $n \in \Z$ nur die diskreten Werte \q{nummeriert}, also \emph{einheitenlos} ist.
Deshalb hat $f \in \R$ lediglich als Einheit \q{Zyklen pro Sample}, was man auch daran sieht, dass f"ur $f = 1$ gilt $x[n] = A \cos(2\pi n + \theta) = A \cos(\theta)$.
Es existiert nun ein wichtiger Unterschied zwischen $x[\cdot]$ von \eqref{eq:discrete_cosine} und $x_a(\cdot)$ von \eqref{eq:analog_cosine}.
Das Signal $x[\cdot]$ ist nur periodisch, falls $f$ eine rationale Zahl ist, also $f = p/q$ f"ur $p,q \in \Z$ und $q \neq 0$.

Wieso?

Ein zeitdiskrtes Signal ist periodisch, falls $x[n + N] = x[n]$ f"ur alle $n \in \Z$.
F"ur unser Signal in \eqref{eq:discrete_cosine} hei"st das also, dass
\[
    \cos(2 \pi f n + \theta) 
        = \cos(2 \pi f (n + N) + \theta)
        = \cos(2 \pi f n + 2 \pi f N + \theta)
\]
Da $\cos$ Periode $2\pi k$ f"ur $k \in \Z$ besitzt, muss $2 \pi f N = 2 \pi k$ gelten, also
\[
    f = \frac kN.
\]
Andersherum kann man die kleinste Periode $N$ ermitteln, indem man $f = k/N$ vollst"andig k"urzt, sodass also Z"ahler und Nenner keine gemeinsamen Teiler mehr haben, und man dann den Nenner des resultierenden Bruches als $N$ setzt. 
Ein Beispiel wird in \Cref{py:disc_harms} gezeigt. 
Man kann interessante Ergebnisse erzielen, wenn man diesen Plot f"ur $\omega=0,\pi/8,\pi/4,\pi/2$ und $\omega=\pi$ erzeugt ("Ubung).
%
\begin{listing}
    \noindent
    \begin{minipage}{0.49\textwidth}
        \strut\vspace*{-\baselineskip}\newline
        \inputminted[firstline=4]{python3}{code/disc_harms.py}
    \end{minipage}%
    \begin{minipage}{0.49\textwidth}
        \strut\vspace*{-\baselineskip}\newline
        \includegraphics[width=\textwidth]{code/disc_harms.png}
    \end{minipage}
    \codecaption{code/disc_harms.py}{Berechnung und Darstellung von \eqref{eq:discrete_cosine}}\label{py:disc_harms}
\end{listing}

Die Signale der Form \eqref{eq:discrete_cosine} haben noch eine andere interessante Eigenschaft, die sich wieder aus der $2\pi$-Periodizit"at von $\cos$ ergibt. 
Betrachten wir noch einmal \eqref{eq:discrete_cosine} und wir finden, dass
\[
\cos(\omega n + \theta) = \cos(\omega n + 2\pi n + \theta) = \cos((\omega + 2\pi) n + \theta).
\]
Das hei"st, dass
\[
    x[n] = \cos(\omega n + \theta) = \cos((\omega + 2\pi k) n + \theta) = x_k[n]
\]
f"ur \emph{alle} $k \in \Z$ gilt.
Das hei"st, dass sich $x_k[\cdot]$ nicht von $x[\cdot]$ unterscheiden l"asst.
Man nennt dann jedes der $x_k[\cdot]$ einen \emph{Alias} von $x[\cdot]$.
Man kann deshalb auch sagen, dass f"ur jedes $\omega$ mit $\Abs{\omega} > \pi$ ein zugeh"origes $\omega_a$ mit $\Abs{\omega_a} < \pi$ existiert, sodass
\[
    \cos(\omega n + \theta) = \cos(\omega_a n + \theta)
\]
gilt.
Vergewissern sie sich von dieser Tatsache, indem sie verschiedene Aliase basierend auf \Cref{py:disc_harms} visualisieren ("Ubung).

Stellen wir uns f"ur einen kurzen Moment vor, dass wir wissen, dass wir $x[n]$ durch Abtastung einer Funktion wie in \eqref{eq:analog_cosine} erhalten haben.
Selbst wenn wir wissen, dass nur \emph{eine} Frequenz in diesem Signal vor Abtastung vorhanden war, k"onnen wir \emph{nicht} entscheiden, welche das war.
%
\FloatBarrier
%
\subsection{Zeit-Kontinuierliche Komplexe Sinussignale}\label{sec:cont_complex_harm}
%
Wir wollen eine bestimmte Menge an Funktionen betrachten. Wir wollen kontinuierliche komplexe Schwingungen betrachten, welche mit einer Frequenz $F_k$ schwingen, welche ein ganzzahliges Vielfaches einer Frequenz $F_0$ ist.
Das hei"st, wir betrachten dann
\[
F_k = k \cdot F_0 \Text{f"ur} k \in \Z \Text{, was}
x_k(t) = \exp(\jmath 2 \pi F_k t) = \exp(\jmath 2 \pi k F_0 t)
\]
ergibt. 
Jedes der $x_k$ hat Periode $1/F_k = T_k = T_0/k$. 
Das hei"st f"ur wachsendes $\Abs{k}$ werden die Perioden immer um ein Vielfaches k"urzer. 
Umgekehrt haben dann alle $x_k$ gemeinsame Periode, $T_0$, da f"ur jedes $k$ gilt, dass $T_k \cdot k = T_0$.
Wir haben auch kein Problem mit Aliasing zwischen den $x_k$, da bei kontinuierlichen Signalen gilt, dass $x_{k_1} \neq x_{k_2}$, falls $k_1 \neq k_2$.

Wie wir in \Cref{sec:signals_vec} gesehen haben, k"onnen wir beliebige Linearkombination aus Signalen bilden und erhalten wieder ein Signal.
Wir k"onnen also f"ur eine Folge von $c_k \in \C$ die Linearkombination der $x_k$ bilden und erhalten
%
\begin{equation}\label{eq:cont_fourier_series}
    x_a = \Sum{k \in \Z}{}{c_k x_k} : \R \rightarrow \C
    \Text{mit} 
    t \mapsto x_a(t) = \Sum{k \in \Z}{}{c_k x_k(t)}
        = \Sum{k \in \Z}{}{c_k \exp(\jmath 2 \pi k F_0 t)}.
\end{equation}
%
Die erste Schreibweise ist absichtlich ohne das Argument $t$, um zu verdeutlichen, dass Signale \emph{wirklich} als eigenst"andige Signale behandelt werden k"onnen und dass $x_a(t) \in \C$ \q{nur} die Auswertung von $x_a$ an der Stelle $t$ ist, welche \emph{strikt} von dem \emph{Vektor} $x_a$ zu unterscheiden ist.

Nat"urlich ist \eqref{eq:cont_fourier_series} als Fourierreihe von $x_a$ bekannt, und die $c_k$ sind die Fourierkoeffizienten von $x_a$.
Wie in \Cref{sec:signals_vec} k"onnen wir also die $c_k$ durch \eqref{eq:cont_fourier_series} mit $x_a$ \emph{identifizieren}, da uns die $c_k$ eine alternative Darstellung von $x_a$ liefern.
%
\subsection{Zeit-Diskrete Komplexe Sinussignale}
%
Analog zu \Cref{sec:cont_complex_harm}, wollen wir uns zeit-diskrete komplexe Schwingungen herleiten, die von einer bestimmten Grundfrequenz definiert werden.
Da wir, im Unterschied zum kontinuierlichen Fall, nicht f"ur alle $f \in \R$ eine periodische Funktion erhalten, w"ahlen wir $f_0 = 1/N$ f"ur ein $N \in \N$. 
Die Intension ist, dass wir so $1/N$ Perioden pro Abtastwert erhalten werden. 
Demzufolge wird die Schwingung mit Frequenz $f_0$ genau Periodenl"ange $N$ haben.
Dann definieren wir die Signale $x_k[\cdot]: \N \rightarrow \C$ als
%
\begin{equation}\label{eq:disc_harms_comp}
    x_k[n] = \exp\left(
        \jmath 2 \pi k f_0 n
    \right) \Text{mit} k \in \Z.
\end{equation}
%
Man sieht nun leicht, dass $f_k = k/N$ immer eine rationale Zahl ist und $x_k[\cdot]$ Periodenl"ange $k/N$ hat, falls $k/N \in \Z$.
Dies ist in \Cref{py:disc_harms_comp} dargestellt.

Au"serdem findet man wieder, dass $x_k[\cdot]$ ein Alias von $x_{k+N}[\cdot]$ sein muss, denn mit $f_0 = 1/N$ ergibt sich
\[
 x_{k+N}[n] = \exp\left(
        \jmath 2 \pi (k + N) f_0 n
    \right)
    = \exp\left(
        \jmath 2 \pi \frac{k + N}{N} n
    \right)
    = \exp\left(
        \jmath 2 \pi \frac{k}{N} n
    \right) 
    \exp\left(
        \jmath 2 \pi \frac NN n
    \right) 
    = x_k[n].
\]
Das hei"st, dass nur $N$ verschiedene $x_k[\cdot]$ existieren.
Normalerweise nimmt man jene $x_k[\cdot]$ f"ur $k = 0, 1, \ldots, N-1$.

\begin{listing}
    \noindent
    \begin{minipage}{0.49\textwidth}
        \strut\vspace*{-\baselineskip}\newline
        \inputminted[firstline=4]{python3}{code/disc_harms_comp.py}
    \end{minipage}%
    \begin{minipage}{0.3\textwidth}
        \strut\vspace*{-\baselineskip}\newline
        \includegraphics[width=\textwidth]{code/disc_harms_comp.png}

        \includegraphics[width=\textwidth]{code/disc_harms_comp_e.png}
    \end{minipage}
    \codecaption{code/disc_harms_comp.py}{Berechnung und Darstellung von \eqref{eq:disc_harms_comp} f"ur $f_0 = 1/16$ und $f_0 = 1/(5 e)$}\label{py:disc_harms_comp}
\end{listing}

Nun k"onnen wir auch wieder, wie in \eqref{eq:cont_fourier_series} eine Linearkombination der $x_k[\cdot]$ bilden.
Man beachte, dass in diesem Fall die Summation nat"urlich \emph{endlich} sein wird, da wir nur $N$ verschiedene $x_k[\cdot]$ zur Verf"ugung haben.
Wir bilden also
\[
    x[\cdot] = \Sum{k = 0}{N-1}{c_k x_k[\cdot]}
\]
und erhalten so ein Signal mit Werten
\begin{equation}\label{eq:disc_fourier_series}
    x[n] 
        = \Sum{k = 0}{N-1}{c_k x_k[n]} 
        = \Sum{k = 0}{N-1}{
            c_k \exp\left(
                \jmath 2 \pi \frac{k}{N} n
            \right) 
        },
\end{equation}
was die Fourierreihe eines diskreten und periodischen Signals darstellt, wobei in diesem Fall der Vektor $\bm c = [c_k]_{k=0}^{N-1} \in \C^N$ eine alternative Repr"asentation des Signals ist.

Das Signal $x[\cdot]$ selbst ist periodisch mit Periodenl"ange $N$, d.h. das Signal ist durch die Werte $\bm x = [x[n]]_{n=0}^{N-1} \in \C^N$ \emph{vollst"andig} definiert. Das hei"st wir k\"onnen das Signal $x[\cdot]$ mit dem \emph{endlich-dimensionalen} Vektor $\bm x \in \C^N$ identifizieren.
Da genauso jedes der $x_k[\cdot]$ auch Periodenl"ange $N$ hat, erhalten wir auf die gleiche Weise Vektoren $\bm x_k \in \C^N$.
Mit diesen endlich-dimensionalen Vektoren sind wir nun in der Lage die Fourierreihe in \eqref{eq:disc_fourier_series} mit \q{normalen} Vektoren durch
%
\begin{equation}\label{eq:disc_fourier_lincomb}
    \bm x = c_1 \bm x_1 + c_2 \bm x_2 + \ldots + c_{N-1} \bm x_{N-1}
\end{equation}
%
auszudr"ucken.
Wir sehen also \emph{direkt}, dass Signale wirklich wie Vektoren behandelt werden k"onnen.

\Cref{eq:disc_fourier_series} kann auch als Abbildung $M : \C^N \rightarrow \C^N$ interpretiert werden, da wir in die rechte Seite von \eqref{eq:disc_fourier_series} einfach ein $\bm c \in \C^N$ stecken k"onnen und wir erhalten das entsprechende $\bm x = M(\bm c)$.
Noch weiter ist die Abbildung $M$ sogar linear, da 
\[
    M(\bm c^1 + \bm c^2)
        =  \Sum{k = 0}{N-1}{
            (c^1_k + c^2_k) \exp\left(
                \jmath 2 \pi \frac{k}{N} n
            \right) 
        }
        =  \Sum{k = 0}{N-1}{
            c^1_k \bm x_k
        }
        + \Sum{k = 0}{N-1}{
            c^2_k \bm x_k 
        }
        = M(\bm c^1) + M(\bm c^2).
\]
Das hei"st, dass es auch eine \emph{Matrix} $\bm M \in \C^{N \times N}$ geben muss, welche uns einfach $\bm c$ in $\bm x$ umtransformiert, indem wir $\bm x = \bm M \cdot \bm c$ als Matrix-Vektor-Produkt berechnen.
Wenn wir \eqref{eq:disc_fourier_lincomb} genau betrachten sehen wir, dass wir die Matrix $\bm M$ bilden k"onnen, indem wir deren $k$-te Spalte $\bm M_{\cdot, k}$ gleich $\bm x_k$ setzen.
Wenn wir noch sicher sein k"onnten, dass $\bm M$ invertierbar ist, k"onnten wir sogar aus $\bm x$ via $\bm c = \bm M^{-1} \cdot \bm x$ die Fourierkoeffizienten $\bm c$ direkt aus einem gegebenen $N$-periodischen Signal $x[\cdot]$ bestimmen.
%
%
\subsection{Abtastung von Sinussignalen}\label{sec:sample_harm}
%
Es gibt viele M"oglichkeiten ein analoges Signal zu digitalisieren.
Wir beschr"anken uns auf Abtastung, welche ein analoges Signal auf eine regelm"a"sige Art und Weise \emph{direkt} auswertet.
Diese Art wird manchmal auch \q{Nyquist-Sampling} genannt, weil die theoretische Grundlage f"ur \q{erfolgreiches} Sampling durch das Nyquist-Theorem gelegt ist.
Wir stellen uns Abtastung so vor, dass wir das Signal $x_a: \R \rightarrow \R$ direkt an gewissen Stellen beobachten k"onnen.
Wir k"onnen uns eine Art Sampling-Operator $\mathcal{S}$ vorstellen, der ein analoges Signal $x_a$ in eine abgetastete Version $x_a \mapsto \mathcal{S}(x_a)[\cdot] = x[\cdot]$ transformiert.
Durch die regelm"a"sige/uniforme Abtastung in Zeitabst"anden $T > 0$ von $x_a$ erhalten wir also
\[
    x[n] = \mathcal{S}(x_a)[n] = x_a(n T) \Text{mit} n \in \Z.
\]
Wir nennen $F_s = T^{-1}$ die Sampling-Frequenz, oder die Abtastrate.
Der Vorgang ist schematisch in \Cref{fig:uniform_sampling} dargestellt.

Da wir uns $x[\cdot]$ so vorstellen, dass es \q{einfach} eine Folge von reellen Zahlen ist, m"ussen wir bei der Interpretation von $x[\cdot]$ auch immer gleichzeitig im Hinterkopf behalten, dass der Wert $x[n]$ dem Wert $x_a(n T) = x_a(n/F_s)$ entspricht.
Das bedeutet, dass $t$ (als Argument von $x_a$) und $n$ (als Argument von $x[\cdot]$) durch
\[
t = n T = n/F_s
\]
miteinander in Verbindung stehen. 
Man sieht auch nun eindrucksvoll, dass dadurch $n = t \cdot F_s$ einheitenlos geworden ist, bzw.~sein muss.
%
\begin{figure}
    \begin{center}
        \includegraphics[width=0.7\textwidth]{img/sampling/uniform_sampling.png}
    \end{center}
    \caption{Uniforme Abtastung einer Signals. Quelle: \cite{proakis2013}}\label{fig:uniform_sampling}
\end{figure}

Weiterhin folgt aus $t = n/F_s$, dass es auch einen Zusammenhang zwischen der Frequenz $F$ einer kontinuierlichen Signals und der Frequenz $f$ im Zeit-diskreten geben muss.
Um diesen herzuleiten, betrachten wir eine einfache analoge Schwingung, wie in \eqref{eq:analog_cosine}, also
\[
x_a(t) = A \cos(2 \pi F t + \theta)
\]
und wir stellen uns vor, dass wir dieses Signal mit Samplerate $F_s = 1/T$ abtasten. Dann erhalten wir zun"achst
\[
x[n] 
    = x_a(n T) 
    = A \cos(2 \pi F n T + \theta) 
    = A \cos\left(\frac{2 \pi F n}{F_s} + \theta\right).
\]
Wenn wir nun $x[n]$ in die Form von \eqref{eq:discrete_cosine} bringen, sehen wir, dass $f = F/F_s$ gelten muss.

Wie ist dies zu interpretieren? 
Wir sind mit dem analogen Signal $x_a$ gestartet, welches die Frequenz $F$ enth"alt.
Durch das Sampling mit Rate $F_s$ entsteht eine abgetastete Schwingung mit Frequenz $f = F/F_s$. 
Doch wir haben bereits gesehen, dass sich die Frequenz $f$ von keiner Frequenzen $f + k$ unterscheiden l"asst.
Das hei"st im Umkehrschluss, dass sich \emph{nach} der Abtastung die urspr"ungliche Frequenz nicht eindeutig bestimmen l"asst, da alle
\[
F_k = F + k \cdot F_s 
\]
bei Abtastung von $A \cos(2 \pi F_k t + \theta)$ diesselben Abtastwerte $x[n]$ ergeben w"urden.
Wenn wir nun also behaupten wollen, dass wir im digitalen irgendetwas sinnvolles zu tun gedenken, dann k"onnen wir dies gerade nicht so ohne weiteres.
Denn bis jetzt haben wir keine M"oglichkeit das wahre analoge Signal zu rekonstruieren.
Diese missliche Lage wird in \Cref{py:aliasing} dargestellt, wo ein m"ogliches
$x_a$, dessen Abtastwerte $x[n]$ und zwei m"ogliche Aliase dargestellt sind.
Man sieht, wie die Aliase so geschaffen sind, dass auch sie Ursprung f"ur die Abtastwerte $x[n]$ sein k"onnten.
%
\begin{listing}
    \noindent
    \begin{minipage}{0.49\textwidth}
        \strut\vspace*{-\baselineskip}\newline
        \inputminted[firstline=4]{python3}{code/aliasing.py}
    \end{minipage}%
    \begin{minipage}{0.49\textwidth}
        \strut\vspace*{-\baselineskip}\newline
        \includegraphics[width=\textwidth]{code/aliasing.png}
    \end{minipage}
    \codecaption{code/aliasing.py}{Visualisierung von $F_k = F + k \cdot F_s$}\label{py:aliasing}
\end{listing}

Die Frage ist nun, wie wir das Sampling gestalten m"ussen, dass wir aus $x[n]$ eindeutig das Signal $x_a$ rekonstruieren k"onnen.
In diesem Fall ist mit \q{rekonstruieren} gemeint, dass wir aus den Werten $x[n]$ den Wert $x_a(t)$ f"ur beliebige $t \in \R$ korrekt bestimmen k"onnen.
Wie wir oben gesehen haben, ist im Digitalen nur sinnvoll von Frequenzen $f \in [-1/2,+1/2]$ zu sprechen, da wir f"ur alle anderen $f^\prime \notin [-1/2,+1/2]$ ein $f \in [-1/2,+1/2]$ finden, das dieselben Werte in \eqref{eq:discrete_cosine} produziert.
Wegen des Zusammenhangs $f = F/F_s$ macht es also Sinn sich auch im \emph{Analogen} auf den entsprechenden Bereich zu beschr"anken.
Das hei"st, wenn wir nur analoge Signale betrachten, bei welchen
\[
-\frac{F_s}2 \leqslant F \leqslant +\frac{F_s}2
\]
gilt, dann sind wir in der Lage aus $x[\cdot]$ das originale $x_a$ zu rekonstruieren, weil wir wissen, auf welche der Aliase wir uns beschr"anken m"ussen.

\emph{Eine M"oglichkeit der perfekten Rekonstruktion von analogen mit einzelnen Frequenzen Signalen aus uniformen digitalen Abtastwerten ist die Einschr"ankung auf einen bestimmten Frequenzbereich.}

Umgekehrt k"onnen wir auch bei Vorwissen "uber die maximale Frequenz $F_{\rm max}$, also $F \in [-F_{\rm max},+F_{\rm max}]$ in einem Signal $x_a$ die Samplingrate ermitteln, sodass im Digitalen die Aliase $f + k$ f"ur $k \neq 0$ nicht im Bereich $[-F_{\rm max},+F_{\rm max}]$ liegen.
Damit
\[
    -\frac 12 \leqslant f \leqslant + \frac 12
\]
gilt, muss also auch
\[
    -\frac 12 \leqslant \frac{F}{F_s} \leqslant + \frac 12 \Text{f"ur alle} F \in [-F_{\rm max},+F_{\rm max}]
\]
gelten.
Deshalb muss schlussendlich $F_s > 2 F_{\rm max}$ gelten.
Es ist zu beachten, dass wir diese "Uberlegungen erst einmal \q{nur} f"ur Signale der Form \eqref{eq:analog_cosine} und \eqref{eq:discrete_cosine} durchgef"uhrt haben.
Im n"achsten Abschnitt werden wir das Abtasttheorem f"ur beliebige aperiodische Signale herleiten.
%
%
\subsection{Das Samplingtheorem}
%
Wir besch"aftigen uns nun also allgemein mit dem Problem der Abtastung eine beliebigen analogen aperiodischen Signals $x_a$ zur Folge
\[
    x[n] = x_a(nT).
\]
F"ur die bequeme Analyse von kontinuierlichen Signalen und ihrem Anteil an harmonischen Komponenten, benutzen wir die \gls{ft} $\mathcal{F}$, welche ein Signal $x : \R \rightarrow \C$ transformiert in $x \mapsto \mathcal{F} x = X : \R \rightarrow \C$, wobei $X$ durch
%
\begin{equation}\label{eq:fourier_trafo}
    X(F) = \Int{-\infty}{+\infty}{x(t) \exp(-\jmath 2 \pi F t)}{t}
\end{equation}
%
definiert ist.
Wir werden versuchen, die Kombination von Klein- und Gro"sbuchstaben $x \leftrightarrow X$ als \gls{ft}-Paar beizubehalten.
Die zugeh"orige inverse \gls{ft}, also die Abbildung von $X$ auf $x$ ist gegeben durch
%
\begin{equation}\label{eq:inv_fourier_trafo}
    x(t) = \Int{-\infty}{+\infty}{X(F) \exp(\jmath 2 \pi F t)}{F}.
\end{equation}

Wir wollen nun ausarbeiten, wie man diese Art Integral-Transformation rein mathematisch interpretieren kann, um eine alternative Sicht auf solche Art Transformation zu erhalten.
Betrachten wir dazu das Signal $x$ wieder als Vektor in einem Vektorraum, in dem ein \emph{Skalarprodukt} definiert ist.
Um zu erl"autern, was das bringt, starten wir mit etwas Bekanntem.
Im endlich-dimensionalen Fall, also wenn $\bm x, \bm y \in \C^N$, dann ist ein m"ogliches Skalarprodukt $\ScPr{\cdot}{\cdot} : \C^N \times \C^N \rightarrow \R$ durch
\[
 \ScPr{\bm x}{\bm y} 
    = \Sum{i = 1}{N}{x_i \cdot y^\ast_i} 
    = y^\herm \cdot x
\]
gegeben, wobei der letzte Ausdruck das Matrix-Vektor-Produkt einer $\C^{N \times 1}$ Matrix und einem Vektor in $\C^N$ darstellt.
Man kann nun $\ScPr{\bm x}{\bm y}$ betrachten, um zu ermitteln, wie \q{"ahnlich} die Vektoren $\bm x$ und $\bm y$ sind.
Beispielsweise nennen wir die beiden Vektoren orthogonal/senkrecht, falls $\ScPr{\bm x}{\bm y} = 0$. 
In diesem Fall interpretieren wir dies intuitiv so, dass $\bm x$ und $\bm y$ keine \q{gemeinsamen} Anteile haben.
Beispielsweise, wenn wir einen dritten Vektor $\bm z = \alpha \bm x + \beta \bm y$ betrachten und es gilt, dass $\ScPr{\bm x}{\bm y} = 0$, dann schl"agt sich dies auch auf das Skalarprodukt von $\ScPr{\bm x}{\bm z}$ nieder, da
%
\[
    \ScPr{\bm x}{\bm z} 
        = \ScPr{\bm x}{\alpha \bm x + \beta \bm y}
        = \alpha \ScPr{\bm x}{\bm x}.
\]
%
Beim Bilden von $\ScPr{\bm x}{\bm z}$ k"onnen wir also einen etwas asymmetrischen Standpunkt einnehmen und uns vorstellen, dass wir ermitteln, wie viele \q{Anteile} von $\bm x$ in $\bm z$ zu finden sind.

Man sieht, dass dies in gewisser Weise erlaubt mit hochdimensionalen Objekten eine Art Geometrie zu betreiben.
Man kann noch weiter gehen und mit einem Skalarprodukt Korrelationen, Winkel und L"angen definieren.

Wir wollen nun dieses Konzept auf kontinuierliche Signale erweitern und dann die \gls{ft} in diesem Licht interpretieren.
Man kann zeigen, dass f"ur zwei Funktionen $x,y : \R \rightarrow \C$ die Abbildung $(x,y) \mapsto \ScPr{x}{y}$ mit
%
\begin{equation}\label{eq:cont_scpr}
    \ScPr{x}{y} = \Int{-\infty}{+\infty}{
        x(t) \cdot y^\ast(t)
    }{t}
\end{equation}
%
ein Skalarprodukt definiert. 
Auch hier halten wir an der Interpretation fest, dass wir damit berechnen, wie "ahnlich sich $x$ und $y$ sind.
Definieren wir nun die Signale $k_F: \R \rightarrow \C$ durch $k_F(t) = \exp(\jmath 2 \pi F t)$, dann k"onnen wir \eqref{eq:fourier_trafo} umschreiben zu
\[
\ScPr{x}{k_F} 
    = \Int{-\infty}{+\infty}{
        x(t) \cdot \exp(\jmath 2 \pi F t)^\ast
    }{t}
    = \Int{-\infty}{+\infty}{
        x(t) \cdot \exp(-\jmath 2 \pi F t)
    }{t}
    = X(f).
\]
Dies suggeriert uns also, dass wir die \gls{ft} als Skalarprodukt von dem zu transformierenden Signal und einem geeignet gew"ahlten Transformationskern interpretieren k"onnen.
Die Zuordnung von $F \mapsto \ScPr{x}{k_F}$ definiert dann im Grunde die Funktion $X$ f"ur alle $F$.

Genauso erhalten wir f"ur die Folge der Abtastwerte $x[\cdot]$ die \gls{dtft} als Skalarprodukt von $x[\cdot]$ und der Folge $k_f[n] = \exp(\jmath 2 \pi f n)$, also
%
\begin{equation}\label{eq:dtft_inner_prod}
    X(f) = \Sum{n \in \Z}{}{
            x[n] k_f[n]^\ast
        }
        = \Sum{n \in \Z}{}{
            x[n] exp(-\jmath 2 \pi f n)
        }.
\end{equation}
%
Die inverse \gls{dtft} ergibt sich durch
\[
x[n] = \Int{-1/2}{+1/2}{X(f) \exp(\jmath 2 \pi f n)}{f}.
\]
Wir haben nun alle Werkzeuge zusammen, um genauer zu Analysieren, was bei Abtastung von $x_a$ zu $x[\cdot]$ geschieht.
Wir erinnern uns, dass gilt f"ur die Abtastpunkte gilt, dass $t = nT = n/F_s$ gilt.
Wir erhalten dann mit $x[n] = x_a(nT)$ und der inversen \gls{ft} angewandt auf $X_a$, dass
\[
x[n] = x_a(nT) = \Int{-\infty}{+\infty}{X_a(F) \exp(\jmath 2 \pi F/F_s n)}{F}
\]
gelten muss.
Setzen wir nun auch f"ur $x[\cdot]$ die inverse \gls{dtft} ein, erhalten wir mit $f = F/F_s$ (siehe \Cref{sec:sample_harm}) als Variablentransformation, dass
\[
    \frac{1}{F_s} \Int{-{F_s}/2}{+{F_s}/2}{X(f) \exp(\jmath 2 \pi F/F_s n)}{F}
    = \Int{-\infty}{+\infty}{X_a(F) \exp(\jmath 2 \pi F/F_s)}{F}
\]
gilt. 
Wichtig ist an diesem Ausdruck, dass wir nun einen Zusammenhang zwischen der \gls{dtft} $X$ und der \gls{ft} $X_a$ gefunden haben.
Die Integration auf beiden Seiten ist auch bez"uglich desselben Integrationskernes $\exp(\jmath 2 \pi \cdot/F_s n)$.
Das hei"st, dass es m"oglich sein sollte, einen Ausdruck herzuleiten, der $X$ in Abh"angigkeit von $X_a$ ausdr"uckt.
Mit ein wenig algebraischem Grindwork findet man
\begin{equation}\label{eq:spectrum_sampled}
    X(f) = F_s \Sum{k \in \Z}{}{
        X_a((f - k) F_s)
    }.
\end{equation}

Wie ist dies nun zu interpretieren? 
Im Grunde best"atigt \eqref{eq:spectrum_sampled} f"ur beliebige Signale, was wir bereits f"ur Signale mit einzelnen Frequenzen (siehe \eqref{eq:analog_cosine}) gefunden hatten.
Das Spektrum wird durch die Abtastung periodifiziert und zwar entsteht das periodische Spektrum $X$ durch Wiederholung von um $1/F_s$ gestauchte Kopien von $X_a$ mit Abstand $1/F_s$.

Andererseits kann man es auch so sehen, dass der Wert $X(f)$ sich ergibt aus Summation der Werte $X_a(f \cdot F_s - k F_s)$ f"ur alle $k \in \Z$. 
Also an der Stelle $f$ erscheinen die Werte von $X_a$ an den Stellen $f F_s - k F_s$.
Das hei"st, wie die Periodifizierung vonstatten geht h"ngt ma"sgeblich von der Samplingfrequenz $F_s$ ab!

Man sieht nun auch wieder sch"on, dass unsere obige Argumentation zum Verh"altnis von Samplingfrequenz und maximaler Frequenz im Signal immernoch gilt, da nun gelten muss, dass \emph{alle} belegten Frequenzen von $x_a$ sich im Intervall $[-F_s/2,+F_s/2]$ befinden m"ussen, da sich sonst die Kopien von $X_a$ in \eqref{eq:spectrum_sampled} "uberlappen.
Dies ist "aquivalent zur Forderung, dass
\[
\Abs{X_a(F)} = 0 \Text{f"ur} \Abs{F} > F_s/2
\]
gelten muss. 
In diesem Fall spricht man davon, dass $X_a$ \emph{bandbegrenzt} ist.
Das kleinste $F \in \R$, was obige Ungleichung erf"ullt, nennen wir $F_{\rm max}$.

Wir sind nun beinahe am Ziel angelangt, dass wir das Samplingtheorem formulieren k"onnen.
Wir ben"otigen lediglich noch eine M"oglichkeit aus den Abtastwerten $x[\cdot]$ das Signal $x_a$ zu rekonstruieren.
Wenn kein Aliasing vorliegt, also $F_{\rm max} < F_s/2$, dann k"onnen wir $X_a$ aus $X$ berechnen, indem wir
\[
X_a(F) = \begin{cases}
    \frac{X(f)}{F_s}, \Abs{F} \leqslant F_s/2, \\
    0 \Text{sonst}
\end{cases}
\]
setzen.
Wir wissen au"serdem, dass sich $X$ durch die \gls{dtft} durch
\[
    X(f) = \Sum{n \in \Z}{}{
        x[n] \exp(-\jmath 2 \pi n F/F_s)
    }
\]
berechnen l"asst.
Weiter k"onnen wir nun auch $x_a$ durch Integration "uber einen endlichen Bereich durch
\[
    x_a(t) = \Int{-F_s/2}{+F_s/2}{X_a(F) \exp(\jmath 2 \pi F t)}{F}.
\]
erhalten. 
Wir setzen nun einfach alles ein und erhalten
\[
x_a(t) = \frac{1}{F_s}\Int{-F_s/2}{+F_s/2}{
    \Sum{n \in \Z}{}{
        x[n] \exp(-\jmath 2 \pi n F/F_s)
    } 
    \exp(\jmath 2 \pi F t)}{F}.
\]
Toll, aber wir m"ussen dies nun noch ein wenig umformen. Zuerst vertauschen wir Integration und Summation, weil wir es d"urfen und nutzen $x[n] = x_a(n/F_s)$. Dies ergibt
\[
x_a(t) = \frac{1}{F_s}\Sum{n \in \Z}{}{
            x_a(n/F_s)
            \Int{-F_s/2}{+F_s/2}{
                \exp(-\jmath 2 \pi n F/F_s)
                \exp(\jmath 2 \pi F t)
            }{F}
        }.
\]
Wir sind nicht wirklich schlauer, aber wir wissen aus unserer Erfahrung von Integration von komplexen Funktionen, dass
\[
    \frac{1}{F_s}\Int{-F_s/2}{+F_s/2}{
        \exp(-\jmath 2 \pi n F/F_s)
        \exp(\jmath 2 \pi F t)
    }{F} = \frac{\sin(\pi F_s (t - n/Fs))}{\pi F_s (t - n/F_s)} = \Sinc(F_s (t - n/Fs)).
\]
Wir nutzen nun wiederum die Interpretation von Integration eines Produktes von Funktionen als deren Skalarprodukt.
Wir bilden also das Skalarprodukt von zwei Funktionen mit Periode $F_s$, d.h. es gen"ugt das Integral im Intervall $[-F_s/2, +F_s/2]$ zu bilden.
Sehen wir genauer hin, bilden wir also das Skalarprodukt $\ScPr{k_t}{k_{n/F_s}}$, wobei "ahnlich wie oben
\[
k_t(F) = \exp(\jmath 2 \pi F t)
\]
definiert wurde.
Das hei"st nun in der Sprache von Skalarprodukten, dass wir die $\Sinc$-Funktion erhalten, als
\[
    \Sinc(F_s (t - n/Fs)) = \ScPr{k_t}{k_{n/F_s}}.
\]
Wenn man es ein wenig allgemeiner Formuliert, kann man sagen, dass die $\Sinc$-Funktion nur ein spezieller \emph{Interpolationskern} ist, der sich aus der Definition von $k_t$ ergibt.
Wir werden sp"ater noch ein weiteres Beispiel f"ur so einen Kern betrachten. Zusammenfassend f"ur diesen \Cref{sec:sampling} steht nun folgendes
\begin{Thm}[Samplingtheorem]\label{stm:sampling_theorem}
Gegeben sei ein analoges Signal $x_a$ mit Frequezen in $[-F_{\rm max},+F_{\rm max}]$ und dessen Abtastwerte $x[\cdot]$ mit $x[n] = x_a(nT)$, wobei $T = 1/F_s$.

Falls $F_s > 2 F_{\rm max}$, dann gilt
\begin{equation}\label{eq:sampling_theorem}
    x_a(t) = \Sum{n \in \Z}{}{
        x[n] \cdot g_{F_s}(t - n T),
    }
\end{equation}
wobei der Interpolationskern $g : \R \rightarrow \R$ gegeben ist durch
\[
g_{F_s}(t) = \frac{\sin(\pi F_s t)}{\pi F_s t}.
\]
\end{Thm}

\textbf{Hinweis:} Das Samplingtheorem, wie es in \cite{proakis2013} formuliert ist, beinhaltet einen kleinen, aber entscheidenden Fehler. Die Definition des Interpolationskernes $g_F$ ist dort mit
\[
g(t) = \frac{\sin(2 \pi B t)}{2 \pi B t}.
\]
gegeben. 
Doch in diesem Falle w"urde der Interpolationskern von der Bandbreite des Signals $x_a$, aber nicht von der Abtastrate $F_s$ abh"angen. 
Die angegebe Definition ist nur korrekt, falls $F_s = 2 B$, wir also mit der \emph{minimalen} Samplerate abgetastet haben.
In diesem Fall spricht man auch von \emph{kritischer Abtastung}.
%
\begin{listing}
    \begin{minipage}{0.49\textwidth}
        \strut\vspace*{-\baselineskip}\newline
        \inputminted[firstline=4]{python3}{code/sampling_theorem.py}
    \end{minipage}
    \begin{minipage}{0.49\textwidth}
        \strut\vspace*{-\baselineskip}\newline
        \includegraphics[width=\textwidth]{code/sampling_theorem.png}
    \end{minipage}
    \codecaption{code/sampling_theorem.py}{Berechnung und Darstellung von \Cref{stm:sampling_theorem}}\label{py:sampling_theorem}
\end{listing}

Es ist weiterhin noch zu erw"ahnen, dass wir genau genommen immer noch nicht wissen, wie wir "uberpr"ufen k"onnen, welche maximale Frequenz $F_{\rm max}$ von einem analogen Signal $x_a$ belegt wird.
Dies liegt daran, dass wir im Vorhinein -- also vor Abtastung -- keinen Zugriff auf das abzutastende Signal haben.
Das hei"st, dass wir auch noch nicht "uberpr"ufen k"onnen, ob wir das Samplingtheorem eingehalten haben, oder einhalten werden, falls wir Abtasten sollten.
Man muss sich also f"ur ein gegebenes System, das einem Signale produziert, die abgetastet werden sollen, auf anderem Weg "uberlegen, wie man die Bedingung $\Abs{X_a(F)} = 0 \Text{f"ur} \Abs{F} > F_s/2$ "uberpr"ufen kann.

\FloatBarrier
