
Wir schränken nun die Menge der Systeme ein, die wir betrachten wollen, indem wir fordern, dass das System $\mathcal{T}$ gleichzeitig linear und zeitinvariant ist.
Das heißt, es gilt einerseits, dass ein Eingang $x[\cdot]$ zum System $\mathcal{T}$ mit Ausgang $y[\cdot]$ bei Verzögerung zu $x[\cdot - k]$ den entsprechend verzögerten Ausgang $y[\cdot - k]$ zur Folge hat.
Gleichzeitig kann der Ausgang des Systems $\mathcal{T}$ für Eingange, die lineare Superpositionen sind als lineare Superposition von den entsprechenden Ausgängen ausgedrückt werden, siehe \Cref{img:disc_sys:linear_sys}.

\subsubsection{Faltungsformel}

Wir wollen die Struktur von \gls{lti}-Systemen ausnutzen, um eine allgemeine und einfache Formel für das Eingangs-Ausgangsverhalten von jenen angeben zu können.
Als Erstes verallgemeinern wir hierzu \Cref{img:disc_sys:linear_sys} zu beliebigen, aber endlichen Summen, also gegeben ist ein Eingang $x[\cdot]$ der Form
%
\begin{equation}\label{eq:lti_sys:input}
    x[n] = \Sum{k=1}{K}{a_k \cdot x_k[n]},
\end{equation}
%
wobei wir annehmen zu wissen, wie die Ausgänge von jedem $x_k[\cdot]$ zu berechnen sind, also
\[
    y_k[n] = (\mathcal{T}x_k[\cdot])[n].
\]
Dann wissen wir wegen der Linearität und \eqref{eq:lti_sys:input}, dass
\begin{equation}\label{eq:lti_sys:superpos}
    y[n] 
        = \left[\mathcal{T}\left(
            \Sum{k=1}{K}{a_k \cdot x_k[\cdot]}
        \right)\right][n] 
        = \Sum{k=1}{K}{
            a_k (\mathcal{T}x_k[\cdot])[n]
        }
        = \Sum{k=1}{K}{
            a_k y_k[n]
        }
\end{equation}
gelten muss.
Es lohnt sich einige Zeit über diese Sache zu meditieren und es gibt verschiedene Interpretationen.
\begin{itemize}
    \item Wie bereits erwähnt passt dies zur linearen Struktur des Systems $\mathcal{T}$.
    \item Ist ein Eingangssignal aus anderen Signalen zusammengesetzt, dann setzt sich die Reaktion des Systems auf dieses zusammengesetzte Signal aus den Reaktionen auf die Signalbausteine zusammen. 
    Wichtig ist hierbei, dass die Art der Zusammensetzung sich nicht ändert. Die $a_k$ in \eqref{eq:lti_sys:superpos} sind die gleichen, wie in \eqref{eq:lti_sys:input}.
\end{itemize}

Wir wollen nun einen Schritt weiter gehen und eine Menge von $x_k[\cdot]$ angeben, die es erlauben \emph{alle} möglichen Signale darzustellen.
Dazu betrachten wir, was geschieht, wenn wir den Einheitsstoß $\delta[\cdot]$ mit einem beliebigen Signal multiplizieren.
Wir rechnen demzufolge für ein beliebiges Signal
\[
x[n] \cdot \delta[n] = \begin{cases}
    x[0] \Text{für} n = 0 \\
    0 \Text{sonst.}
\end{cases}
\]
Wenn wir nun die Einheitsstöße verschieben um $k \in \Z$ erhalten wir
\[
    x[n] \cdot \delta[n-k] = \begin{cases}
        x[k] \Text{für} n = k \\
        0 \Text{sonst.}
    \end{cases}
\]
Im Grunde \q{pickt} $\delta[\cdot-k]$ bei Multiplikation den Wert von $x[\cdot]$ an der Stelle $k$ heraus.
Deshalb können wir nun schreiben
\begin{equation}
    x[n] = \Sum{k \in \Z}{}{
        x[k] \cdot \delta[n-k],
    }
\end{equation}
was nach Definition von $x_k[\cdot] = \delta[\cdot - k]$ genau die Form von \eqref{eq:lti_sys:input} mit $a_k = x[k]$ annimmt.

Die Werte des Eingangssignals werden demnach zu den Faktoren in der Linearkombination der $x_k[\cdot] = \delta[\cdot - k]$.
Die Kernbeobachtung ist also, dass jedes $x_k[\cdot]$ eine verschobene Kopie von $\delta[\cdot]$ ist. 
Das heißt, dass wir nun die \gls{lti}-Eigenschaft ausnutzen können, weil \eqref{eq:lti_sys:superpos} impliziert, dass wir nur $(\mathcal{T}\delta[\cdot])[\cdot]$ berechnen müssen und $(\mathcal{T}\delta[\cdot - k])[\cdot]$ sich wegen der Zeitinvarianz als $(\mathcal{T}\delta[\cdot])[\cdot - k]$ ergibt -- und das ohne Rechnen!

Wir geben dem Kind nun einen Namen, also definieren wir $h: \Z \rightarrow \C$ als die Antwort des Systems $\mathcal{T}$ auf den Eingang $\delta[\cdot]$, also
\begin{equation}\label{eq:lti_sys:ir}
    h[n] = (\mathcal{T} \delta[\cdot])[n].
\end{equation}
Man nennt $h[\cdot]$ die \emph{Impulsantwort} des Systems.
Dann können wir mit \eqref{eq:lti_sys:superpos} folgern, dass
\begin{equation}\label{eq:lti_sys:conv}
    y[n] 
        = (\mathcal{T} x[\cdot])[n] 
        = \Sum{k \in \Z}{}{
            x[k] h[n-k]
        }
\end{equation}
gelten muss.
Doch diese Art der Operation kennen wir sehr gut -- es ist eine gewöhnliche Faltung von zwei diskreten Signalen!

Das heißt, dass sich die Antwort $y[\cdot]$ eines diskreten \gls{lti}-Systems aus der \emph{Faltung} des Einganges $x[\cdot]$ mit der Impulsantwort $h[\cdot]$ ergibt.
Wir schreiben in Kurzform
\[
    y[n] = (x \ast h)[n] = (h \ast x)[n].
\]
Es wird sich zeigen, dass sich viele Eigenschaften des Systems $\mathcal{T}$ aus oft signifikant einfacher zu prüfenden Eigenschaften der Impulsantwort $h[\cdot]$ ergeben.
Das heißt, dass $h[\cdot]$ in gewisser Weise das System $\mathcal{T}$ \emph{vollständig repräsentiert}.
%
\begin{listing}
    \noindent
    \begin{minipage}{0.49\textwidth}
        \strut\vspace*{-\baselineskip}\newline
        \inputminted[firstline=10,lastline=22]{python3}{code/moving_average.py}
    \end{minipage}%
    \begin{minipage}{0.49\textwidth}
        \strut\vspace*{-\baselineskip}\newline
        \includegraphics[width=\textwidth]{code/moving_average.png}
    \end{minipage}
    \codecaption{dsv/code/moving_average.py}{Gleitendes Mittel mit Länge $\ell=4$. Wir vergleichen die direkte Berechnung mit der Berechnung über die Faltung}\label{py:moving_average}
\end{listing}

In \Cref{py:moving_average} zeigen wir das Verhalten eines gleitenden Mittelwertes (\emph{moving average}), welches sich durch
\[
y[n] = \frac{1}{\ell} \Sum{k=0}{k=\ell}{x[n-k]}
\]
ergibt.
Man sieht schön, dass durch das Mitteln die (in diesem Fall) zufällige Eingabe-Sequenz am Ausgang geglättet erscheint.
Wichtig bei diesem Beispiel ist die Tatsache, dass wir direkt einsehen, dass Anwendung der direkten Formel für das gleitende Mittel aus eine Eingabe $x[\cdot]$ denselben Effekt hat, wie die Faltung mit $h[\cdot]$, das sich aus der Anwendung der Mittelung auf $\delta[\cdot]$ ergibt.

Es lohnt sich, sich einige Eigenschaften der Faltung zu merken. 
Diese sind:
\begin{itemize}
    \item Bi-Linearität: Es gilt $(a_1 x_1[\cdot] + a_2 x_2[\cdot]) \ast h[\cdot] = a_1 (x_1 \ast h)[\cdot] + a_2 (x_2 \ast h)[\cdot]$. 
    Dies ist die \q{normale} Linearität in den Eingängen, die sich aus der Linearität des Systems $\mathcal{T}$ ergibt. 
    Es gilt aber auch $(x \ast (a_1 h_1 + a_2 h_2))[\cdot] = a_1 (x \ast h_1)[\cdot] + a_2 (x \ast h_2)[\cdot]$.
    Das heißt, wenn wir ein System $\mathcal{T} = a_1 \mathcal{T}_1 + a_2 \mathcal{T}_2$ gegeben haben, dann ist die Impulsantwort des Systems $\mathcal{T}$ die gleiche Linearkombination der Impulsantworten $h_1[\cdot]$ und $h_2[\cdot]$ der beiden Systeme $\mathcal{T}_{1,2}$.
    Das heißt wiederum, dass \gls{lti}-Systeme selbst ein linearer Raum sind!
    Wir sprechen hier von \emph{Bi}-Linearität, weil die Faltung eben linear in zwei Argumenten ist.
    \item Die Faltung ist assoziativ: Es gilt also, dass $(x \ast h_1) \ast h_2 = x \ast (h_1 \ast h_2)$. 
    Dies impliziert, dass die Verkettung von zwei \gls{lti}-Systemen wieder ein \gls{lti}-system ergibt, wobei sich die Impulsantwort der Verkettung durch Faltung der beiden Impulsantworten der verketteten Systeme ergibt.
    \item Kommmutativität: Es gilt $h_1 \ast h_2 = h_2 \ast h_1$, demnach auch, dass $x \ast (h_1 \ast h_2) = x \ast (h_2 \ast h_1)$.
    Das heißt erstaunlicherweise, dass man verkettete \gls{lti}-Systeme in ihrer Reihenfolge vertauschen kann, ohne das Eingangs-Ausgangsverhalten des Gesamtsystems zu beeinflussen.
\end{itemize}

\begin{listing}
    \noindent
    \begin{minipage}{0.40\textwidth}
        \strut\vspace*{-\baselineskip}\newline
        \inputminted[firstline=10,lastline=33]{python3}{code/ramp_ma.py}
    \end{minipage}%
    \begin{minipage}{0.59\textwidth}
        \strut\vspace*{-\baselineskip}\newline
        \includegraphics[width=\textwidth]{code/ramp_ma.png}
    \end{minipage}
    \codecaption{dsv/code/ramp_ma.py}{Verkettung von mehreren Moving Averages der Länge $\ell = 3$.}\label{py:ramp_ma}
\end{listing}
%
In \Cref{py:ramp_ma} untersuchen wir einige der oben genannten Eigenschaften.
Einerseits sehen wir, dass die Impulsantwort von $\texttt{MA}(\texttt{MA2}(\cdot))$ mit der von $\texttt{MA2}(\texttt{MA}(\cdot))$ identisch ist. Wir haben also Kommutativität nachgeprüft.
Wir sehen außerdem, dass sich die Impulsantwort der Verkettung aus Faltung der einzelnen Impulsantworten ergibt.
Aus dem abgetasteten \q{Rechteck} wird nach nochmaliger Anwendung ein abgetastetes, aber breiteres, \q{Dreieck}, was schlussendlich zu einer abgetasteten, stückweise quadratischen, Impulsantwort wird.
Generell kann man das komplette System als eine dreifache Verkettung gleitender Mittel der Länge $\ell=3$ verstehen.
Außerdem bestätigt \Cref{py:ramp_ma} bei Vergleich der verschiedenen Ausgänge, dass wiederholtes Mitteln am Ausgang mit Anzahl der Mittelungen zunehmend \q{glattere} Signale erzeugt.
%
%
%
%
%
\subsubsection{Eigenschaften von \texorpdfstring{\acrshort*{lti}}{LTI}-Systemen}\label{sec:lti_sys:properties}
%
\paragraph{\texorpdfstring{\gls{bibo}}{BIBO}-Stabilität}
Wir hatten vorher schon diesen Begriff der Stabiliät eingeführt und formulieren nun eine Bedingung an $h[\cdot]$, die es uns erlaubt auf Stabilität zu prüfen.
Wir nennen einen Eingang $x[\cdot]$ beschränkt, falls ein $M_x < \infty$ existiert, sodass
\[
\Abs{x[n]} \leqslant M_x \Text{für alle} n \in \Z
\]
erfüllt ist.
Dann können wir mit der Faltungsformel \eqref{eq:lti_sys:conv} berechnen, dass
\[
\Abs{y[n]} 
    = \Abs{\Sum{k\in\Z}{}{x[k] h[n-k]}} 
    \leqslant \Sum{k\in\Z}{}{\Abs{x[k] h[n-k]}} 
    \leqslant M_x \Sum{k\in\Z}{}{\Abs{h[n-k]}} 
\]
gilt.
Damit nun $\Abs{y[n]} < \infty$, muss also gelten, dass
\[
    \Sum{k\in\Z}{}{\Abs{h[n-k]}} < \infty.
\]
Das heißt, \emph{wenn} $h[\cdot]$ absolut summierbar ist, dann ist das System mit $h[\cdot]$ als Impulsantwort \gls{bibo}-stabil.

Wie ist es um die umgekehrte Schlussfolgerung bestellt?
Impliziert \gls{bibo}-Stabilität, dass $h[\cdot]$ absolut summierbar sein muss?
Erinnern wir uns daran, dass man \gls{bibo}-Stabilität widerlegen kann, indem man \emph{einen} beschränkten Eingang $x[\cdot]$ findet, für welchen der Ausgang $y[\cdot]$ nicht beschränkt bleibt.
Nehmen wir an, dass 
\[
\Sum{k\in\Z}{}{\Abs{h[n-k]}} = \infty
\]
und betrachten wir den Eingang
\[
x[n] = \begin{cases}
    \frac{h[-n]^\ast}{\Abs{h[-n]}}, \Text{für} h[n] \neq 0 \\
    0 \Text{sonst.}
\end{cases}
\]
Man sieht, dass $\Abs{x[n]} \leqslant 1$, es ist also beschränkt.
Dann berechnen wir einfach den ersten Wert am Ausgang mit \eqref{eq:lti_sys:conv} und der Definition des Einganges $x[\cdot]$, also
\[
y[0] 
    = \Sum{k\in\Z}{}{x[-k] h[k]}
    = \Sum{k\in\Z}{}{
        \frac{\Abs{h[k]}^2}{\Abs{h[k]}}
    }
    = \Sum{k\in\Z}{}{
        \Abs{h[k]}
    }
    = \infty,
\]
wobei das letzte Gleichheitszeichen gilt, weil wir angenommen hatten, dass $h[\cdot]$ nicht absolut summierbar ist.
Man kann also schlussfolgern, dass sich Stabilität vollständig durch die Impulsantwort $h[\cdot]$ bestimmen lässt, weil absolute Summierbarkeit der Impulsantwort \emph{äquivalent} zur \gls{bibo}-Stabilität ist.
Eine tolle Sache!
%
\paragraph{\texorpdfstring{\acrshort*{fir}}{FIR} vs. \texorpdfstring{\acrshort*{iir}}{IIR} Systeme}
%
Gilt für die Impulsantwort $h[\cdot]$, dass
\[
h[n] = 0, \Text{für} n < m, M \leqslant n
\]
für zwei Zahlen $m \leqslant M$, dann bezeichnet man das zugehörige System $\mathcal{T}$ als \gls{fir}-System.
Ist obige Bedingung nicht erfüllt, so nennt man $\mathcal{T}$ ein \gls{iir}-System.
Bei \gls{fir}-Systemen sind für die Berechnung von $y[n]$ nur endlich viele Werte, maximal $M - m$ viele, notwendig.
Das System hat also ein endliches Gedächtnis der Länge $M - m$, wobei \gls{iir}-Systeme ein unendlich langes Gedächtnis haben.
Sobald bei einem \gls{fir}-System $\Abs{h[n]} < \infty$ für alle $n \in \Z$ gilt, ist es auch stabil -- also sind in der Praxis \emph{alle} \gls{fir}-Systeme stabil.

Bei einem \gls{iir}-System ist die Frage nach Stabilität nicht so einfach zu beantworten, doch wir werden im Folgenden noch ein Werkzeug kennenlernen, mit welchem dies einfach nachzuprüfen sein wird.
Außerdem haben \gls{iir}-Systeme noch das Problem, dass man die Faltungsformel \eqref{eq:lti_sys:conv} nicht nutzen kann, um ein \gls{iir}-System zu \emph{implementieren}.
%
%
\subsubsection{Rekursive \texorpdfstring{\acrshort*{iir}}{IIR}-Systeme}
%
%
Um die Notwendigkeit von \eqref{eq:lti_sys:conv} zu umgehen, betrachten wir eine gewisse Klasse von Systemen, deren Ausgang $y[\cdot]$ auch über einen alternativen Weg bestimmt werden kann.
Hierzu betrachten wir
\[
y[n] = \frac{1}{n+1}\Sum{k=0}{n}{x[n]},
\]
was ein kumulatives Mittel von $0$ bis $n$ darstellt.
So wie es hier scheint, muss man für die Berechnung von $y[n]$ alle vergangenen Werte von $x[\cdot]$ bereitliegen haben.
Doch mit einer einfachen Umformung findet man, dass
\[
(n+1)y[n] = n y[n-1] + x[n] 
\Leftrightarrow 
y[n] = \frac{n}{n+1} y[n-1] + \frac{1}{n+1} x[n].
\]
Wir können also alternativ $y[n]$ aus $x[n]$ und $y[n-1]$ berechnen.
Da also $y[n]$ von $y[n-1]$ abhängt, nennen wir das System \emph{rekursiv}.
Man sieht deutlich, dass diese Umformulierung deutlich macht, dass wir nur $y[n-1]$ im Speicher halten müssen und dieses mit einer Art \emph{zeitverzögertem Feedback} ausstatten müssen.
Hierbei ist natürlich die Zeitverzögerung essenziell, denn müssen wir $y[n]$ in Abhängigkeit von $y[n]$ berechnen, würde uns das vor ein halbwegs unlösbares Problem stellen.
In \Cref{py:cumulative_sum} sehen wir die beiden unterschiedlichen Implementierungen.
Es ist hier zu beachten, dass \mintinline{python}|y[nn] = np.sum(x[:nn]) / (nn + 1)| immer auf die komplette Vergangenheit von $x[\cdot]$ zugreift und eben \emph{nicht} auf Werte von $y[\cdot]$.

\begin{listing}
    \noindent
    \begin{minipage}{0.49\textwidth}
        \strut\vspace*{-\baselineskip}\newline
        \inputminted[firstline=5,lastline=20]{python3}{code/cumulative_sum.py}
    \end{minipage}%
    \begin{minipage}{0.49\textwidth}
        \strut\vspace*{-\baselineskip}\newline
        \includegraphics[width=\textwidth]{code/cumulative_sum.png}
    \end{minipage}
    \codecaption{dsv/code/cumulative_sum.py}{Die beiden möglichen Implementierungen eines kumulativen Mittelwertes}\label{py:cumulative_sum}
\end{listing}
%
%
Für rekursive Systeme entsteht noch das Problem, dass wir beispielsweise für den Beginn der rekursiven Berechnung von $y[n]$ ab einem gewissen $n_0 \in \Z$ den Wert $y[n_0-1]$ kennen müssen.
Das heißt wir benötigen einen \emph{Startwert} für die Rekursion.
Dieser beeinflusst auch maßgeblich das Verhalten des Systems.

Eine Möglichkeit, wie man das produktiv ausnutzen kann, ist für die Berechnung der Quadratwurzel einer positiven reellen Zahl $A$.
Für die Herleitung definieren wir erst die Funktion $f : \R \rightarrow \R$ via
\[
f(x) = x^2 - A.
\]
Wie man leicht sieht, hat diese Funktion Nullstellen $x_{1,2} = \pm \sqrt{A}$.
Die sogenannte Newton-Iteration~\linkfootnote{{https://encyclopediaofmath.org/index.php?title=Newton_method}} berechnet iterativ via
\[
y[n] = y[n-1] - \frac{f(y[n-1])}{f^\prime(y[n-1])}
\]
eine Nullstelle der Funktion $f$.
Setzen wir unsere Funktion ein und definieren $x[\cdot] = A u[\cdot]$, dann erhalten wir
\[
y[n] = \frac 12 \left(
    y[n-1] + \frac{x[n]}{y[n-1]}.
\right)
\]
Nutzen wir einen geeigneten Startwert, beispielsweise $y[-1] = 1$, so erhalten wir eine \emph{sehr schnell} konvergierende Folge von $y[n]$.

\begin{listing}
    \noindent
    \begin{minipage}{0.49\textwidth}
        \strut\vspace*{-\baselineskip}\newline
        \inputminted[firstline=5,lastline=15]{python3}{code/square_root.py}
    \end{minipage}%
    \begin{minipage}{0.49\textwidth}
        \strut\vspace*{-\baselineskip}\newline
        \includegraphics[width=\textwidth]{code/square_root.png}
    \end{minipage}
    \codecaption{dsv/code/square_root.py}{Iteratives Verfahren zur Berechnung von $\sqrt{A}$}\label{py:square_root}
\end{listing}
%
%
Die Folge konvergiert so schnell, dass bereits nach $5$ Iterationen der Fehler an der endlichen Genauigkeit von Gleitkommaarithmetik kratzt.
Es ist auch darauf hinzuweisen, dass das System nur sehr einfache arithmetische Operationen benutzt, um die numerisch nicht ganz triviale Berechnung von $\sqrt{A}$ beliebig genau und sehr schnell zu approximieren.

Abschließend ist noch anzumerken, dass man rekursive Systeme auch \q{lösen} kann, siehe \cite[Kap.~2.4.3]{proakis2013}, indem man aus der rekursiven Vorschrift eine explizite entwickelt. 
Die dort entwickelte Theorie erinnert der Lösung von Differenzialgleichungen nach Funktionen, nur werden stattdessen Differenzengleichungen nach diskreten Folgen gelöst.
%
%
\subsubsection{Approximation von \texorpdfstring{\acrshort*{iir}}{IIR}-Systemen durch \texorpdfstring{\acrshort*{fir}}{FIR}-Systeme}
Um die Faltungsformel doch anwenden zu können, kann man für ein \emph{stabiles} \gls{iir}-System mit Impulsantwort $h[\cdot]$ eine \gls{fir}-Approximation finden.
Ein weiterer Vorteil ergibt sich dann, dass auch dieses resultierende System stabil sein muss.
Für $n_{\rm low} < n_{\rm hgh}$ definieren wir
\[
h_{\rm FIR}[n] = \begin{cases}
    h[n], \Text{falls} n_{\rm low} \leqslant n \leqslant n_{\rm hgh}, \\
    0 \Text{sonst.}
\end{cases}
\]
Da aus der Stabilität von dem System mit Impulsantwort $h[\cdot]$ folgt, dass
\[
    \lim\limits_{k \rightarrow \infty} 
        \Sum{n = k}{\infty}{
            \left(\Abs{h[n]} + \Abs{h[-n]}\right)
        } = 0,
\]
da sonst
\[
    \Sum{n \in \Z}{\infty}{\Abs{h[n]}}
\]
nicht endlich sein könnte.
Das heißt, dass die Werte der Impulsantwort $h[\cdot]$ gegen $0$ konvergieren müssen und deshalb kann man $n_{\rm low} < n_{\rm hgh}$ so wählen, dass der Unterschied zwischen $h[\cdot]$ und $h_{\rm FIR}[\cdot]$ beliebig klein wird.

Je nachdem wie schnell $h[\cdot]$ gegen $0$ konvergiert, benötigen wir mehr oder von $0$ verschiedene Einträge in $h_{\rm FIR}$, was sich auf den Implementierungsaufwand auswirkt.

Ein Beispiel für einen exponentiellen Mittelwert-Filter findet man in \Cref{py:exp_mean}.
Man sieht, dass für $\alpha=0.5$ der Abschneidefehler deutlicher zutage tritt, da die Faltung mit $h_{\rm FIR}[\cdot]$ in diesem Fall ein deutlich schlechteres Ergebnis liefert als im Falle von $\alpha=0.1$.
Dies liegt eben daran, dass bei $\alpha=0.1$ der \gls{iir}-Filter \emph{effektiv} ein \gls{fir}-Filter wird.
Wir wollen aber darauf hinweisen, dass es eine ganz eigene Theorie für die Approximation von Filtern durch andere Filter gibt, die wir hier nicht einmal anreißen wollen.

\begin{listing}
    \noindent
    \begin{minipage}{0.49\textwidth}
        \strut\vspace*{-\baselineskip}\newline
        \inputminted[firstline=5,lastline=33]{python3}{code/exp_mean.py}
    \end{minipage}%
    \begin{minipage}{0.49\textwidth}
        \strut\vspace*{-\baselineskip}\newline
        \includegraphics[width=\textwidth]{code/exp_mean.png}
    \end{minipage}
    \codecaption{dsv/code/exp_mean.py}{Approximation eines exponentiellen Mittelwertes, also einem \acrshort*{iir}-System, durch ein \acrshort*{fir}-System}\label{py:exp_mean}
\end{listing}
